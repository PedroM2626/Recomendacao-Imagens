{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "# Sistema de Recomendação por Imagens\n",
    "\n",
    "Este notebook documenta e demonstra o projeto de recomendação por similaridade visual. O sistema utiliza uma CNN pré-treinada (ResNet) para extrair embeddings das imagens e medir similaridade via cosseno.\n",
    "\n",
    "Pipeline: coleta de imagens → extração de embeddings ResNet → normalização L2 → similaridade por cosseno → top-K resultados.\n",
    "\n",
    "Principais componentes:\n",
    "- `ImageEmbedder`: extrai embeddings da imagem.\n",
    "- `index_images`: percorre um diretório, gera embeddings e salva o índice (`index.npz`).\n",
    "- `recommend`: consulta o índice e retorna os itens mais similares.\n",
    "- `write_jsonl`: persiste a saída em JSONL.\n",
    "\n",
    "Consulte o README para instruções completas de CLI e testes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-md",
   "metadata": {},
   "source": [
    "## Instalação\n",
    "\n",
    "Instale dependências (se necessário):\n",
    "\n",
    "```\n",
    "pip install torch torchvision pillow numpy python-dotenv\n",
    "```\n",
    "\n",
    "Opcional (Jupytext):\n",
    "\n",
    "```\n",
    "jupytext --version\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffb4db2",
   "metadata": {},
   "source": [
    "### Importação de Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6f337fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações da biblioteca padrão\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "import tempfile\n",
    "import shutil\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Importações de terceiros para manipulação de arrays e imagens\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b37a7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Tenta carregar variáveis de ambiente de um arquivo .env, se existir\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    # Ignora se a biblioteca dotenv não estiver instalada ou falhar\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306fc4",
   "metadata": {},
   "source": [
    "### Importações de Deep Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49824d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações do PyTorch e Torchvision para modelos de visão computacional\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd40fc79",
   "metadata": {},
   "source": [
    "### Utilitário de Cronometragem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9a01bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"Classe utilitária para medir tempo de execução.\"\"\"\n",
    "    def __init__(self):\n",
    "        # Marca o tempo inicial na instanciação\n",
    "        self.t = time.time()\n",
    "    def tick(self) -> float:\n",
    "        # Calcula a diferença de tempo desde a última chamada ou inicialização\n",
    "        now = time.time()\n",
    "        d = now - self.t\n",
    "        self.t = now\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d927eb",
   "metadata": {},
   "source": [
    "### Configurações Globais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "425f0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as extensões de imagem suportadas pelo sistema\n",
    "SUPPORTED_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "list-images-header",
   "metadata": {},
   "source": [
    "### Listagem de Imagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "list-images-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images(root: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Varre um diretório recursivamente em busca de imagens com extensões suportadas.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(root):\n",
    "        raise FileNotFoundError(f\"Diretório não encontrado: {root}\")\n",
    "    out = []\n",
    "    for base, _, files in os.walk(root):\n",
    "        for f in files:\n",
    "            ext = os.path.splitext(f)[1].lower()\n",
    "            if ext in SUPPORTED_EXTS:\n",
    "                out.append(os.path.join(base, f))\n",
    "    if not out:\n",
    "        raise RuntimeError(\"Nenhuma imagem suportada foi encontrada\")\n",
    "    # Retorna a lista ordenada para garantir consistência no índice\n",
    "    return sorted(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb63b46",
   "metadata": {},
   "source": [
    "### Pré-processamento de Imagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "471219b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _default_transforms() -> T.Compose:\n",
    "    \"\"\"\n",
    "    Define as transformações padrão para alimentar a ResNet.\n",
    "    \"\"\"\n",
    "    return T.Compose([\n",
    "        T.Resize(256),       # Redimensiona a imagem\n",
    "        T.CenterCrop(224),   # Corta o centro 224x224\n",
    "        T.ToTensor(),        # Converte para Tensor do PyTorch\n",
    "        # Normaliza com as médias e desvios padrão do ImageNet\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d069da",
   "metadata": {},
   "source": [
    "### Motor de Extração de Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9c81d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEmbedder:\n",
    "    \"\"\"\n",
    "    Classe responsável por carregar o modelo e extrair vetores de características (embeddings).\n",
    "    \"\"\"\n",
    "    def __init__(self, device: str = \"cpu\", model_name: str = \"resnet50\"):\n",
    "        # Define o dispositivo (CPU ou GPU)\n",
    "        self.device = torch.device(device if torch.cuda.is_available() or device == \"cpu\" else \"cpu\")\n",
    "        self.model_name = model_name\n",
    "        # Carrega o modelo e as transformações\n",
    "        self.model, self.transform = self._load_model_and_transform()\n",
    "        self.model.eval() # Modo de avaliação (não treina)\n",
    "        self.model.to(self.device) # Move para o dispositivo correto\n",
    "\n",
    "    def _load_model_and_transform(self):\n",
    "        \"\"\"Carrega a arquitetura ResNet pré-treinada.\"\"\"\n",
    "        weights = None\n",
    "        transform = None\n",
    "        model = None\n",
    "        try:\n",
    "            # Tenta carregar com pesos atualizados da ImageNet\n",
    "            if self.model_name == \"resnet50\":\n",
    "                weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "                model = models.resnet50(weights=weights)\n",
    "                transform = weights.transforms()\n",
    "            elif self.model_name == \"resnet18\":\n",
    "                weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "                model = models.resnet18(weights=weights)\n",
    "                transform = weights.transforms()\n",
    "            else:\n",
    "                # Fallback para ResNet50\n",
    "                weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "                model = models.resnet50(weights=weights)\n",
    "                transform = weights.transforms()\n",
    "        except Exception:\n",
    "            # Fallback para pesos None e transforms manuais se falhar (ex: sem internet ou versão antiga)\n",
    "            if self.model_name == \"resnet18\":\n",
    "                model = models.resnet18(weights=None)\n",
    "            else:\n",
    "                model = models.resnet50(weights=None)\n",
    "            transform = _default_transforms()\n",
    "        \n",
    "        # Remove a última camada (classificador) para obter apenas as features\n",
    "        backbone = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "        return backbone, transform\n",
    "\n",
    "    def embed(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Gera o vetor de embedding para uma única imagem.\"\"\"\n",
    "        if not os.path.isfile(image_path):\n",
    "            raise FileNotFoundError(f\"Arquivo não encontrado: {image_path}\")\n",
    "        try:\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Falha ao abrir imagem: {image_path}: {str(e)}\")\n",
    "            \n",
    "        # Executa a inferência sem calcular gradientes\n",
    "        with torch.inference_mode():\n",
    "            x = self.transform(img).unsqueeze(0).to(self.device) # Adiciona dimensão de batch\n",
    "            feat = self.model(x)\n",
    "            feat = feat.view(feat.size(0), -1) # Flatten\n",
    "            v = feat[0].detach().cpu().numpy().astype(np.float32) # Converte para numpy\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c64b82",
   "metadata": {},
   "source": [
    "### Persistência de Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "98e4c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_index(embeddings: np.ndarray, paths: List[str], out_path: str):\n",
    "    \"\"\"Salva os embeddings e os caminhos dos arquivos em um arquivo comprimido .npz.\"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "    # Salva arrays numpy comprimidos\n",
    "    np.savez_compressed(out_path, embeddings=embeddings, paths=np.array(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa1e3e",
   "metadata": {},
   "source": [
    "### Carregamento de Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2875ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index(index_path: str) -> Tuple[np.ndarray, List[str]]:\n",
    "    \"\"\"Carrega o índice de embeddings do disco.\"\"\"\n",
    "    if not os.path.isfile(index_path):\n",
    "        raise FileNotFoundError(f\"Índice não encontrado: {index_path}\")\n",
    "    z = np.load(index_path, allow_pickle=True)\n",
    "    emb = z[\"embeddings\"].astype(np.float32)\n",
    "    paths = list(z[\"paths\"].tolist())\n",
    "    # Validação básica da integridade dos dados\n",
    "    if emb.ndim != 2 or len(paths) != emb.shape[0]:\n",
    "        raise RuntimeError(\"Índice inválido\")\n",
    "    return emb, paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4337cb",
   "metadata": {},
   "source": [
    "### Normalização Vetorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "370c8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rows(mat: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normaliza as linhas de uma matriz (L2 norm) para cálculo de similaridade de cosseno.\"\"\"\n",
    "    # Calcula a norma L2 de cada linha\n",
    "    n = np.linalg.norm(mat, axis=1, keepdims=True)\n",
    "    # Evita divisão por zero\n",
    "    n[n == 0] = 1.0\n",
    "    return mat / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f7d35",
   "metadata": {},
   "source": [
    "### Função Principal de Indexação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "11a60cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_images(image_dir: str, out_path: str, device: str = \"cpu\", model_name: str = \"resnet50\", batch_size: int = 1) -> Tuple[np.ndarray, List[str]]:\n",
    "    \"\"\"Processo completo de indexação: lista imagens -> gera embeddings -> salva.\"\"\"\n",
    "    timer = Timer()\n",
    "    paths = list_images(image_dir)\n",
    "    embeder = ImageEmbedder(device=device, model_name=model_name)\n",
    "    vecs = []\n",
    "    \n",
    "    # Itera sobre todas as imagens encontradas\n",
    "    for p in paths:\n",
    "        try:\n",
    "            v = embeder.embed(p)\n",
    "            vecs.append(v)\n",
    "        except Exception as e:\n",
    "            # Loga erro mas continua o processo\n",
    "            print(json.dumps({\"erro\": str(e), \"arquivo\": p}))\n",
    "    \n",
    "    if not vecs:\n",
    "        raise RuntimeError(\"Nenhuma embedding foi gerada\")\n",
    "    \n",
    "    # Empilha vetores em uma matriz\n",
    "    E = np.vstack(vecs)\n",
    "    # Normaliza para permitir busca por produto escalar (cosseno)\n",
    "    E = normalize_rows(E)\n",
    "    \n",
    "    # Salva o resultado\n",
    "    save_index(E, paths[:E.shape[0]], out_path)\n",
    "    \n",
    "    # Imprime estatísticas\n",
    "    print(json.dumps({\"tempo_segundos\": round(timer.tick(), 3), \"imagens_indexadas\": E.shape[0], \"dim\": int(E.shape[1])}))\n",
    "    return E, paths[:E.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6eba0d",
   "metadata": {},
   "source": [
    "### Função Principal de Recomendação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5aeac1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(index_path: str, query_image: str, topk: int = 5, device: str = \"cpu\", model_name: str = \"resnet50\") -> List[Tuple[str, float]]:\n",
    "    \"\"\"Realiza a recomendação buscando imagens similares no índice.\"\"\"\n",
    "    # Carrega o índice existente\n",
    "    emb, paths = load_index(index_path)\n",
    "    emb = normalize_rows(emb)\n",
    "    \n",
    "    # Gera embedding da imagem de consulta\n",
    "    embeder = ImageEmbedder(device=device, model_name=model_name)\n",
    "    q = embeder.embed(query_image)\n",
    "    q = q.astype(np.float32)\n",
    "    \n",
    "    # Normaliza o vetor de consulta\n",
    "    qn = q / (np.linalg.norm(q) + 1e-12)\n",
    "    \n",
    "    # Calcula similaridade (produto escalar de vetores normalizados = similaridade de cosseno)\n",
    "    scores = emb.dot(qn)\n",
    "    \n",
    "    # Ordena decrescentemente pelos scores\n",
    "    idx = np.argsort(-scores)[:max(1, topk)]\n",
    "    \n",
    "    # Retorna os caminhos e scores dos top-k\n",
    "    return [(paths[i], float(scores[i])) for i in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0cf5d",
   "metadata": {},
   "source": [
    "### Saída de Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "03315963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jsonl(items: List[Tuple[str, float]], out_path: str):\n",
    "    \"\"\"Escreve os resultados da recomendação em formato JSON Lines.\"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for p, s in items:\n",
    "            f.write(json.dumps({\"path\": p, \"score\": round(s, 6)}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-md",
   "metadata": {},
   "source": [
    "### Visualização de Resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "visualize-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(path: str, title: str = \"\"):\n",
    "    \"\"\"Exibe uma imagem usando matplotlib.\"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_recommendations(query_path: str, recommendations: List[Tuple[str, float]]):\n",
    "    \"\"\"Plota a imagem de consulta e as recomendações lado a lado.\"\"\"\n",
    "    n = len(recommendations)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Mostra consulta\n",
    "    plt.subplot(1, n + 1, 1)\n",
    "    show_image(query_path, \"Consulta\")\n",
    "    \n",
    "    # Mostra recomendados\n",
    "    for i, (path, score) in enumerate(recommendations):\n",
    "        plt.subplot(1, n + 1, i + 2)\n",
    "        show_image(path, f\"Sim: {score:.2f}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5150c907",
   "metadata": {},
   "source": [
    "### Interface de Linha de Comando (CLI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "926385fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parser() -> argparse.ArgumentParser:\n",
    "    \"\"\"Configura os argumentos da linha de comando.\"\"\"\n",
    "    parser = argparse.ArgumentParser(prog=\"image_recommender\", description=\"Sistema de recomendação por imagens baseado em embeddings de CNN\")\n",
    "    sub = parser.add_subparsers(dest=\"cmd\", required=False)\n",
    "\n",
    "    # Subcomando 'index'\n",
    "    p_index = sub.add_parser(\"index\", help=\"Indexa diretório de imagens\")\n",
    "    p_index.add_argument(\"--images\", required=False, default=os.getenv(\"IMAGE_DIR\", \"images\"))\n",
    "    p_index.add_argument(\"--out\", required=False, default=os.getenv(\"INDEX_PATH\", \"index.npz\"))\n",
    "    p_index.add_argument(\"--device\", required=False, default=os.getenv(\"DEVICE\", \"cpu\"))\n",
    "    p_index.add_argument(\"--model\", required=False, default=os.getenv(\"MODEL_NAME\", \"resnet50\"))\n",
    "\n",
    "    # Subcomando 'recommend'\n",
    "    p_rec = sub.add_parser(\"recommend\", help=\"Gera recomendações para uma imagem de consulta\")\n",
    "    p_rec.add_argument(\"--index\", required=False, default=os.getenv(\"INDEX_PATH\", \"index.npz\"))\n",
    "    p_rec.add_argument(\"--query\", required=True)\n",
    "    p_rec.add_argument(\"--topk\", type=int, required=False, default=5)\n",
    "    p_rec.add_argument(\"--out\", required=False, default=\"recommendations.jsonl\")\n",
    "    p_rec.add_argument(\"--device\", required=False, default=os.getenv(\"DEVICE\", \"cpu\"))\n",
    "    p_rec.add_argument(\"--model\", required=False, default=os.getenv(\"MODEL_NAME\", \"resnet50\"))\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07972dd1",
   "metadata": {},
   "source": [
    "### Função Principal (Main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "167440b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Função orquestradora da aplicação.\"\"\"\n",
    "    parser = make_parser()\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Verifica se algum comando foi passado\n",
    "    if not args.cmd:\n",
    "        parser.print_help()\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # Executa o comando escolhido\n",
    "    if args.cmd == \"index\":\n",
    "        try:\n",
    "            index_images(args.images, args.out, device=args.device, model_name=args.model)\n",
    "        except Exception as e:\n",
    "            print(json.dumps({\"erro\": str(e)}))\n",
    "            sys.exit(1)\n",
    "    elif args.cmd == \"recommend\":\n",
    "        try:\n",
    "            items = recommend(args.index, args.query, topk=int(args.topk), device=args.device, model_name=args.model)\n",
    "            write_jsonl(items, args.out)\n",
    "            print(json.dumps({\"recomendacoes\": len(items), \"saida\": args.out}))\n",
    "        except Exception as e:\n",
    "            print(json.dumps({\"erro\": str(e)}))\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        parser.print_help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-md",
   "metadata": {},
   "source": [
    "## Demonstração Interativa\n",
    "\n",
    "Use a interface abaixo para escolher uma imagem do seu dataset e ver as recomendações visuais em tempo real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "interactive-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando índice inicial...\n",
      "{\"tempo_segundos\": 4.229, \"imagens_indexadas\": 30, \"dim\": 2048}\n",
      "Selecione uma imagem abaixo e clique no botão:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55631d670c74a468af7ef982cf43ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Imagem:', options=('./dataset\\\\carlos.png', './dataset\\\\carlos_2.jpg', '.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configurações básicas\n",
    "images_dir = \"./dataset\"\n",
    "index_path = \"./dataset_index.npz\"\n",
    "device = os.getenv(\"cpu\")\n",
    "model_name = \"resnet50\"\n",
    "\n",
    "# 1. Indexação Automática (se necessário)\n",
    "if not os.path.exists(index_path):\n",
    "    print(\"Gerando índice inicial...\")\n",
    "    index_images(images_dir, index_path, device=device, model_name=model_name)\n",
    "\n",
    "# 2. Interface Interativa\n",
    "all_images = list_images(images_dir)\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=all_images,\n",
    "    description='Imagem:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Encontrar Semelhantes\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        query = dropdown.value\n",
    "        print(f\"Processando: {query}...\")\n",
    "        try:\n",
    "            results = recommend(index_path, query, topk=5, device=device, model_name=model_name)\n",
    "            plot_recommendations(query, results)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro: {e}\")\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "print(\"Selecione uma imagem abaixo e clique no botão:\")\n",
    "display(widgets.VBox([dropdown, button, output]))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
