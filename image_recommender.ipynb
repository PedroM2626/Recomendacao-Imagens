{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "# Sistema de Recomendação por Imagens\n",
    "\n",
    "Este notebook documenta e demonstra o projeto de recomendação por similaridade visual. O sistema utiliza uma CNN pré-treinada (ResNet) para extrair embeddings das imagens e medir similaridade via cosseno.\n",
    "\n",
    "Pipeline: coleta de imagens → extração de embeddings ResNet → normalização L2 → similaridade por cosseno → top-K resultados.\n",
    "\n",
    "Principais componentes:\n",
    "- `ImageEmbedder`: extrai embeddings da imagem.\n",
    "- `index_images`: percorre um diretório, gera embeddings e salva o índice (`index.npz`).\n",
    "- `recommend`: consulta o índice e retorna os itens mais similares.\n",
    "- `write_jsonl`: persiste a saída em JSONL.\n",
    "\n",
    "Consulte o README para instruções completas de CLI e testes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-md",
   "metadata": {},
   "source": [
    "## Instalação\n",
    "\n",
    "Instale dependências (se necessário):\n",
    "\n",
    "```\n",
    "pip install torch torchvision pillow numpy python-dotenv\n",
    "```\n",
    "\n",
    "Opcional (Jupytext):\n",
    "\n",
    "```\n",
    "jupytext --version\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f337fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "import tempfile\n",
    "import shutil\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49824d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.t = time.time()\n",
    "    def tick(self) -> float:\n",
    "        now = time.time()\n",
    "        d = now - self.t\n",
    "        self.t = now\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf88985",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images(root: str) -> List[str]:\n",
    "    if not os.path.isdir(root):\n",
    "        raise FileNotFoundError(f\"Diretório não encontrado: {root}\")\n",
    "    out = []\n",
    "    for base, _, files in os.walk(root):\n",
    "        for f in files:\n",
    "            ext = os.path.splitext(f)[1].lower()\n",
    "            if ext in SUPPORTED_EXTS:\n",
    "                out.append(os.path.join(base, f))\n",
    "    if not out:\n",
    "        raise RuntimeError(\"Nenhuma imagem suportada foi encontrada\")\n",
    "    return sorted(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471219b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _default_transforms() -> T.Compose:\n",
    "    return T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c81d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEmbedder:\n",
    "    def __init__(self, device: str = \"cpu\", model_name: str = \"resnet50\"):\n",
    "        self.device = torch.device(device if torch.cuda.is_available() or device == \"cpu\" else \"cpu\")\n",
    "        self.model_name = model_name\n",
    "        self.model, self.transform = self._load_model_and_transform()\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def _load_model_and_transform(self):\n",
    "        weights = None\n",
    "        transform = None\n",
    "        model = None\n",
    "        try:\n",
    "            if self.model_name == \"resnet50\":\n",
    "                weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "                model = models.resnet50(weights=weights)\n",
    "                transform = weights.transforms()\n",
    "            elif self.model_name == \"resnet18\":\n",
    "                weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "                model = models.resnet18(weights=weights)\n",
    "                transform = weights.transforms()\n",
    "            else:\n",
    "                weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "                model = models.resnet50(weights=weights)\n",
    "                transform = weights.transforms()\n",
    "        except Exception:\n",
    "            if self.model_name == \"resnet18\":\n",
    "                model = models.resnet18(weights=None)\n",
    "            else:\n",
    "                model = models.resnet50(weights=None)\n",
    "            transform = _default_transforms()\n",
    "        backbone = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "        return backbone, transform\n",
    "\n",
    "    def embed(self, image_path: str) -> np.ndarray:\n",
    "        if not os.path.isfile(image_path):\n",
    "            raise FileNotFoundError(f\"Arquivo não encontrado: {image_path}\")\n",
    "        try:\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Falha ao abrir imagem: {image_path}: {str(e)}\")\n",
    "        with torch.inference_mode():\n",
    "            x = self.transform(img).unsqueeze(0).to(self.device)\n",
    "            feat = self.model(x)\n",
    "            feat = feat.view(feat.size(0), -1)\n",
    "            v = feat[0].detach().cpu().numpy().astype(np.float32)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_index(embeddings: np.ndarray, paths: List[str], out_path: str):\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "    np.savez_compressed(out_path, embeddings=embeddings, paths=np.array(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index(index_path: str) -> Tuple[np.ndarray, List[str]]:\n",
    "    if not os.path.isfile(index_path):\n",
    "        raise FileNotFoundError(f\"Índice não encontrado: {index_path}\")\n",
    "    z = np.load(index_path, allow_pickle=True)\n",
    "    emb = z[\"embeddings\"].astype(np.float32)\n",
    "    paths = list(z[\"paths\"].tolist())\n",
    "    if emb.ndim != 2 or len(paths) != emb.shape[0]:\n",
    "        raise RuntimeError(\"Índice inválido\")\n",
    "    return emb, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rows(mat: np.ndarray) -> np.ndarray:\n",
    "    n = np.linalg.norm(mat, axis=1, keepdims=True)\n",
    "    n[n == 0] = 1.0\n",
    "    return mat / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a60cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_images(image_dir: str, out_path: str, device: str = \"cpu\", model_name: str = \"resnet50\", batch_size: int = 1) -> Tuple[np.ndarray, List[str]]:\n",
    "    timer = Timer()\n",
    "    paths = list_images(image_dir)\n",
    "    embeder = ImageEmbedder(device=device, model_name=model_name)\n",
    "    vecs = []\n",
    "    for p in paths:\n",
    "        try:\n",
    "            v = embeder.embed(p)\n",
    "            vecs.append(v)\n",
    "        except Exception as e:\n",
    "            print(json.dumps({\"erro\": str(e), \"arquivo\": p}))\n",
    "    if not vecs:\n",
    "        raise RuntimeError(\"Nenhuma embedding foi gerada\")\n",
    "    E = np.vstack(vecs)\n",
    "    E = normalize_rows(E)\n",
    "    save_index(E, paths[:E.shape[0]], out_path)\n",
    "    print(json.dumps({\"tempo_segundos\": round(timer.tick(), 3), \"imagens_indexadas\": E.shape[0], \"dim\": int(E.shape[1])}))\n",
    "    return E, paths[:E.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeac1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(index_path: str, query_image: str, topk: int = 5, device: str = \"cpu\", model_name: str = \"resnet50\") -> List[Tuple[str, float]]:\n",
    "    emb, paths = load_index(index_path)\n",
    "    emb = normalize_rows(emb)\n",
    "    embeder = ImageEmbedder(device=device, model_name=model_name)\n",
    "    q = embeder.embed(query_image)\n",
    "    q = q.astype(np.float32)\n",
    "    qn = q / (np.linalg.norm(q) + 1e-12)\n",
    "    scores = emb.dot(qn)\n",
    "    idx = np.argsort(-scores)[:max(1, topk)]\n",
    "    return [(paths[i], float(scores[i])) for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03315963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jsonl(items: List[Tuple[str, float]], out_path: str):\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for p, s in items:\n",
    "            f.write(json.dumps({\"path\": p, \"score\": round(s, 6)}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926385fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parser() -> argparse.ArgumentParser:\n",
    "    parser = argparse.ArgumentParser(prog=\"image_recommender\", description=\"Sistema de recomendação por imagens baseado em embeddings de CNN\")\n",
    "    sub = parser.add_subparsers(dest=\"cmd\", required=False)\n",
    "\n",
    "    p_index = sub.add_parser(\"index\", help=\"Indexa diretório de imagens\")\n",
    "    p_index.add_argument(\"--images\", required=False, default=os.getenv(\"IMAGE_DIR\", \"images\"))\n",
    "    p_index.add_argument(\"--out\", required=False, default=os.getenv(\"INDEX_PATH\", \"index.npz\"))\n",
    "    p_index.add_argument(\"--device\", required=False, default=os.getenv(\"DEVICE\", \"cpu\"))\n",
    "    p_index.add_argument(\"--model\", required=False, default=os.getenv(\"MODEL_NAME\", \"resnet50\"))\n",
    "\n",
    "    p_rec = sub.add_parser(\"recommend\", help=\"Gera recomendações para uma imagem de consulta\")\n",
    "    p_rec.add_argument(\"--index\", required=False, default=os.getenv(\"INDEX_PATH\", \"index.npz\"))\n",
    "    p_rec.add_argument(\"--query\", required=True)\n",
    "    p_rec.add_argument(\"--topk\", type=int, required=False, default=5)\n",
    "    p_rec.add_argument(\"--out\", required=False, default=\"recommendations.jsonl\")\n",
    "    p_rec.add_argument(\"--device\", required=False, default=os.getenv(\"DEVICE\", \"cpu\"))\n",
    "    p_rec.add_argument(\"--model\", required=False, default=os.getenv(\"MODEL_NAME\", \"resnet50\"))\n",
    "\n",
    "    parser.add_argument(\"--run-tests\", action=\"store_true\", help=\"Executa testes unitários, integração e aceitação\")\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d601ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_dummy_images(root: str) -> List[str]:\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "    paths = []\n",
    "    rng = np.random.default_rng(42)\n",
    "    colors = [(220, 20, 60), (65, 105, 225), (34, 139, 34), (255, 165, 0), (128, 0, 128)]\n",
    "    for i, c in enumerate(colors):\n",
    "        img = Image.new(\"RGB\", (256, 256), c)\n",
    "        arr = np.array(img)\n",
    "        noise = rng.integers(0, 20, size=arr.shape, dtype=np.uint8)\n",
    "        arr = np.clip(arr + noise, 0, 255)\n",
    "        img = Image.fromarray(arr)\n",
    "        p = os.path.join(root, f\"dummy_{i}.jpg\")\n",
    "        img.save(p)\n",
    "        paths.append(p)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac71cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_unit_tests() -> List[str]:\n",
    "    results = []\n",
    "    tmp = tempfile.mkdtemp(prefix=\"recommender_unit_\")\n",
    "    try:\n",
    "        images = _create_dummy_images(tmp)\n",
    "        embeder = ImageEmbedder(device=\"cpu\", model_name=os.getenv(\"MODEL_NAME\", \"resnet50\"))\n",
    "        v = embeder.embed(images[0])\n",
    "        assert isinstance(v, np.ndarray)\n",
    "        assert v.ndim == 1\n",
    "        assert v.size >= 256\n",
    "        results.append(\"unit_embeddings_shape_ok\")\n",
    "        E, paths = index_images(tmp, os.path.join(tmp, \"index.npz\"), device=\"cpu\", model_name=os.getenv(\"MODEL_NAME\", \"resnet50\"))\n",
    "        assert E.shape[0] == len(paths)\n",
    "        assert E.ndim == 2\n",
    "        results.append(\"unit_index_build_ok\")\n",
    "    finally:\n",
    "        shutil.rmtree(tmp, ignore_errors=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffad50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_integration_tests() -> List[str]:\n",
    "    results = []\n",
    "    tmp = tempfile.mkdtemp(prefix=\"recommender_integ_\")\n",
    "    try:\n",
    "        images = _create_dummy_images(tmp)\n",
    "        idx_path = os.path.join(tmp, \"index.npz\")\n",
    "        index_images(tmp, idx_path, device=\"cpu\", model_name=os.getenv(\"MODEL_NAME\", \"resnet50\"))\n",
    "        recs = recommend(idx_path, images[0], topk=3, device=\"cpu\", model_name=os.getenv(\"MODEL_NAME\", \"resnet50\"))\n",
    "        assert len(recs) == 3\n",
    "        assert isinstance(recs[0][0], str) and isinstance(recs[0][1], float)\n",
    "        results.append(\"integration_recommendations_ok\")\n",
    "    finally:\n",
    "        shutil.rmtree(tmp, ignore_errors=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_acceptance_tests() -> List[str]:\n",
    "    results = []\n",
    "    tmp = tempfile.mkdtemp(prefix=\"recommender_accept_\")\n",
    "    try:\n",
    "        images = _create_dummy_images(tmp)\n",
    "        idx_path = os.path.join(tmp, \"index.npz\")\n",
    "        cmd_index = [sys.executable, os.path.abspath(__file__), \"index\", \"--images\", tmp, \"--out\", idx_path]\n",
    "        p1 = subprocess.Popen(cmd_index, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        out1, err1 = p1.communicate()\n",
    "        if p1.returncode != 0:\n",
    "            raise RuntimeError(f\"Falha CLI index: {err1.decode('utf-8', 'ignore')}\")\n",
    "        cmd_rec = [sys.executable, os.path.abspath(__file__), \"recommend\", \"--index\", idx_path, \"--query\", images[0], \"--topk\", \"2\", \"--out\", os.path.join(tmp, \"recs.jsonl\")]\n",
    "        p2 = subprocess.Popen(cmd_rec, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        out2, err2 = p2.communicate()\n",
    "        if p2.returncode != 0:\n",
    "            raise RuntimeError(f\"Falha CLI recommend: {err2.decode('utf-8', 'ignore')}\")\n",
    "        results.append(\"acceptance_cli_flow_ok\")\n",
    "    finally:\n",
    "        shutil.rmtree(tmp, ignore_errors=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167440b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = make_parser()\n",
    "    args = parser.parse_args()\n",
    "    if args.run_tests:\n",
    "        all_results = []\n",
    "        try:\n",
    "            all_results.extend(run_unit_tests())\n",
    "            all_results.extend(run_integration_tests())\n",
    "            all_results.extend(run_acceptance_tests())\n",
    "        except Exception as e:\n",
    "            print(json.dumps({\"tests\": \"failed\", \"erro\": str(e)}))\n",
    "            sys.exit(1)\n",
    "        print(json.dumps({\"tests\": \"passed\", \"results\": all_results}))\n",
    "        return\n",
    "    if not args.cmd:\n",
    "        parser.print_help()\n",
    "        sys.exit(0)\n",
    "    if args.cmd == \"index\":\n",
    "        try:\n",
    "            index_images(args.images, args.out, device=args.device, model_name=args.model)\n",
    "        except Exception as e:\n",
    "            print(json.dumps({\"erro\": str(e)}))\n",
    "            sys.exit(1)\n",
    "    elif args.cmd == \"recommend\":\n",
    "        try:\n",
    "            items = recommend(args.index, args.query, topk=int(args.topk), device=args.device, model_name=args.model)\n",
    "            write_jsonl(items, args.out)\n",
    "            print(json.dumps({\"recomendacoes\": len(items), \"saida\": args.out}))\n",
    "        except Exception as e:\n",
    "            print(json.dumps({\"erro\": str(e)}))\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        parser.print_help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-md",
   "metadata": {},
   "source": [
    "## Uso no Notebook\n",
    "\n",
    "Após executar as células de definição (acima), use as células abaixo para indexar e recomendar.\n",
    "Extensões suportadas: `.jpg`, `.jpeg`, `.png`, `.bmp`, `.webp`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usage-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: indexar e recomendar dentro do notebook\n",
    "images_dir = os.getenv(\"IMAGE_DIR\", \"images\")\n",
    "index_path = os.getenv(\"INDEX_PATH\", \"index.npz\")\n",
    "device = os.getenv(\"DEVICE\", \"cpu\")\n",
    "model = os.getenv(\"MODEL_NAME\", \"resnet50\")\n",
    "\n",
    "if os.path.isdir(images_dir):\n",
    "    E, paths = index_images(images_dir, index_path, device=device, model_name=model)\n",
    "    print(f\"Indexado: {len(paths)} imagens, dim={E.shape[1]}\")\n",
    "else:\n",
    "    print(f\"Diretório de imagens não encontrado: {images_dir}\")\n",
    "\n",
    "# Para consultar, defina o caminho de uma imagem existente e descomente:\n",
    "query_img = \"consulta.jpg\"\n",
    "if os.path.isfile(query_img):\n",
    "    recs = recommend(index_path, query_img, topk=5, device=device, model_name=model)\n",
    "    for p, s in recs:\n",
    "        print(p, round(s, 4))\n",
    "else:\n",
    "    print(f\"Imagem de consulta não encontrada: {query_img}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
